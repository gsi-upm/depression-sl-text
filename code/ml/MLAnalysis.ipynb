{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# import LinearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3052011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_classifier(clf_name):\n",
    "    if clf_name == 'LogR':\n",
    "        return LogisticRegression(max_iter=1000, random_state=24091993, class_weight='balanced')\n",
    "    elif clf_name == 'LinSVM':\n",
    "        return LinearSVC(max_iter=1000, random_state=24091993, class_weight='balanced')\n",
    "    \n",
    "def select_params(clf_name):\n",
    "    if clf_name == 'LogR':\n",
    "        return {'C': np.logspace(-4, 4, 20)}\n",
    "    elif clf_name == 'LinSVM':\n",
    "        return {'C': np.logspace(-4, 4, 20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['depression_severity', 'dep_sign']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $M_f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pad = ['Valence', 'Valence_nwords', 'Arousal', 'Arousal_nwords', 'Dominance', 'Dominance_nwords', \n",
    "                'Longing_GALC', 'Lust_GALC', 'Arousal_GI',\n",
    "                 'Wlbgain_Lasswell', \n",
    "                'Wlbloss_Lasswell', 'Wlbphys_Lasswell', 'Wlbpsyc_Lasswell', 'Wlbtot_Lasswell',\n",
    "                'hu_liu_prop', 'polarity']\n",
    "\n",
    "features_emotion = ['Admiration/Awe_GALC', 'Amusement_GALC', 'Anger_GALC', 'Anxiety_GALC', \n",
    "                    'Boredom_GALC', 'Contempt_GALC', 'Contentment_GALC', 'Desperation_GALC', \n",
    "                    'Disappointment_GALC', 'Disgust_GALC', 'Dissatisfaction_GALC', 'Envy_GALC', 'Fear_GALC', \n",
    "                    'Feelinglove_GALC', 'Guilt_GALC', 'Happiness_GALC', 'Hatred_GALC', \n",
    "                    'Hope_GALC', 'Interest/Enthusiasm_GALC', 'Irritation_GALC', 'Jealousy_GALC', \n",
    "                    'Joy_GALC', 'Pleasure/Enjoyment_GALC', 'Pride_GALC', 'Relaxation/Serenity_GALC', 'Relief_GALC', \n",
    "                    'Sadness_GALC', 'Shame_GALC', 'Tension/Stress_GALC', 'Positive_GALC', 'Negative_GALC',\n",
    "                   'Negativ_GI', 'Ngtv_GI', 'Hostile_GI', 'No_GI', 'Pain_GI', 'Fail_GI', 'Negate_GI',\n",
    "                   'Positiv_GI', 'Pstv_GI', 'Pleasur_GI', 'Yes_GI', 'Feel_GI', 'Emot_GI',\n",
    "                   'Affloss_Lasswell', 'Wlbloss_Lasswell', 'Endslw_Lasswell', 'Anomie_Lasswell', 'Negaff_Lasswell', \n",
    "                    'Notlw_Lasswell', 'Affoth_Lasswell', 'Afftot_Lasswell', 'Meanslw_Lasswell',\n",
    "                   'Affgain_Lasswell', 'Posaff_Lasswell', \n",
    "                    'hu_liu_pos_perc', 'hu_liu_neg_perc', 'hu_liu_pos_nwords', 'hu_liu_neg_nwords',\n",
    "                   'Anger_EmoLex', 'Disgust_EmoLex', 'Fear_EmoLex', 'Negative_EmoLex', 'Sadness_EmoLex', 'Joy_EmoLex', 'Positive_EmoLex',\n",
    "                    'Surprise_EmoLex', 'Anticipation_EmoLex', 'joy_component', 'fear_and_digust_component', 'Sv_GI',\n",
    "                    'pleasantness', 'sensitivity', 'vader_negative', 'vader_neutral', 'vader_compound', 'vader_positive']\n",
    "\n",
    "sentiment = ['negative_adjectives_component', 'positive_adjectives_component', 'polarity_nouns_component', \n",
    "             'polarity_verbs_component', 'virtue_adverbs_component', 'positive_nouns_component', \n",
    "            'positive_verbs_component', 'well_being_component', 'Surelw_Lasswell', 'If_Lasswell']\n",
    "\n",
    "\n",
    "mood = ['Virtue_GI', 'Vice_GI',\n",
    "       'attention', 'aptitude', 'affect', 'posemo',\n",
    "       'negemo', 'anx', 'anger', 'sad']\n",
    "\n",
    "social = ['Beingtouched_GALC', 'Compassion_GALC', 'Gratitude_GALC', 'Humility_GALC', 'Surprise_GALC', 'Submit_GI', \n",
    "                   'Trust_EmoLex', 'Affpt_Lasswell', 'Wlbpt_Lasswell', 'Affil_GI', 'Role_GI', 'Coll_GI', 'Powcon_Lasswell', 'Powcoop_Lasswell', \n",
    "                   'Work_GI', 'Ritual_GI', 'Socrel_GI', 'Race_GI', 'Kin_2_GI', 'Male_GI', 'Female_GI', 'Nonadlt_GI',\n",
    "                   'Hu_GI', 'Social_GI', 'Rel_GI', 'Intrj_GI', 'Ipadj_GI', 'Indadj_GI', 'Powaupt_Lasswell', 'Powpt_Lasswell', 'Powdoct_Lasswell', 'Powauth_Lasswell', \n",
    "                   'social_order_component', 'affect_friends_and_family_component', 'respect_component', 'trust_verbs_component', 'Ptlw_Lasswell', 'Wltpt_Lasswell',\n",
    "                    'Active_GI', 'Passive_GI',  'Rspgain_Lasswell', 'Rsploss_Lasswell', 'Rspoth_Lasswell', 'Rsptot_Lasswell',\n",
    "                    'Rcethic_Lasswell', 'Rcloss_Lasswell', 'Rcgain_Lasswell',\n",
    "                   'social',\n",
    "       'family', 'friend', 'female', 'male']\n",
    "\n",
    "syntactic = ['Self_GI', 'Our_GI', 'You_GI', 'Name_GI', 'politeness_component', 'formlw_Lasswell', 'nwords',\n",
    "          'Comnobj_GI', 'Comform_GI', 'Com_GI', 'WC', 'Analytic',\n",
    "       'Clout', 'Authentic', 'Tone', 'WPS', 'Sixltr',\n",
    "       'Dic', 'function', 'pronoun', 'ppron', 'i',\n",
    "       'we', 'you', 'shehe', 'they', 'ipron',\n",
    "       'article', 'prep', 'auxverb', 'adverb', 'conj',\n",
    "       'negate', 'verb', 'adj', 'compare', 'interrog',\n",
    "       'number', 'quant', 'informal', 'swear', 'netspeak', 'assent',\n",
    "       'nonflu', 'filler', 'AllPunc', 'Period',\n",
    "       'Comma', 'Colon', 'SemiC', 'QMark', 'Exclam',\n",
    "       'Dash', 'Quote', 'Apostro', 'Parenth',\n",
    "       'OtherP'] + ['readability_Kincaid',\n",
    " 'readability_ARI',\n",
    " 'readability_Coleman-Liau',\n",
    " 'readability_FleschReadingEase',\n",
    " 'readability_GunningFogIndex',\n",
    " 'readability_LIX',\n",
    " 'readability_SMOGIndex',\n",
    " 'readability_RIX',\n",
    " 'readability_DaleChallIndex',\n",
    " 'readability_characters_per_word',\n",
    " 'readability_syll_per_word',\n",
    " 'readability_words_per_sentence',\n",
    " 'readability_sentences_per_paragraph',\n",
    " 'readability_type_token_ratio',\n",
    " 'readability_directspeech_ratio',\n",
    " 'readability_characters',\n",
    " 'readability_syllables',\n",
    " 'readability_words',\n",
    " 'readability_wordtypes',\n",
    " 'readability_sentences',\n",
    " 'readability_paragraphs',\n",
    " 'readability_long_words',\n",
    " 'readability_complex_words',\n",
    " 'readability_complex_words_dc',\n",
    " 'readability_tobeverb',\n",
    " 'readability_auxverb',\n",
    " 'readability_conjunction',\n",
    " 'readability_pronoun',\n",
    " 'readability_preposition',\n",
    " 'readability_nominalization',\n",
    " 'readability_interrogative',\n",
    " 'readability_article',\n",
    " 'readability_subordination']\n",
    "\n",
    "topic = ['Goal_GI', 'Try_GI', 'Means_GI', 'Persist_GI', 'Complet_GI', 'Finish_GI',\n",
    "          'Exert_GI', 'Fetch_GI', 'Ovrst_GI', 'Undrst_GI', 'Causal_GI', 'Ought_GI', 'Powoth_Lasswell', \n",
    "                'Powtot_Lasswell', 'Wlttran_Lasswell', 'Wltoth_Lasswell', 'Wlttot_Lasswell', \n",
    "          'Eval_2_GI', 'Eval_GI', 'Iav_GI', 'Ani_GI', 'Aquatic_GI', 'Land_GI', 'Sky_GI', 'Object_GI', 'Tool_GI',\n",
    "            'Food_GI', 'Vehicle_GI', 'Bldgpt_GI', 'Natobj_GI', 'Bodypt_GI', 'Natrpro_GI', 'Color_GI',\n",
    "         'Increas_GI', 'Decreas_GI', 'Quality_GI', 'Quan_GI', 'Numb_GI', 'Ord_GI', 'Card_GI', 'Freq_GI', 'Dist_GI',\n",
    "         'Place_GI', 'Region_GI', 'Route_GI', 'Begin_GI', 'Stay_GI', 'Rise_GI', 'Travel_GI', 'Fall_GI', 'Time_2_GI',\n",
    "         'Time_GI', 'Space_GI', 'Pos_GI', 'Dim_GI', 'Doctrin_GI', 'Econ_2_GI', 'Exch_GI', 'Econ_GI', 'Legal_GI',\n",
    "         'Milit_GI', 'Polit_2_GI', 'Polit_GI', 'Relig_GI', 'Say_GI',\n",
    "         'Academ_GI', 'Exprsv_GI', 'Need_GI', 'Vary_GI', 'Think_GI', 'Know_GI', 'Perceiv_GI', 'Compare_GI', 'Solve_GI',\n",
    "        'Abs_2_GI', 'Abs_GI', 'action_component', 'economy_component', 'certainty_component', 'failure_component',\n",
    "         'Rcrelig_Lasswell', 'Strong_GI', 'Power_GI', 'Weak_GI', 'Powgain_Lasswell', \n",
    "                'Powloss_Lasswell', 'Powends_Lasswell', 'Powaren_Lasswell', \n",
    "          'Rcends_Lasswell', 'Rctot_Lasswell', 'Sklpt_Lasswell', 'Skloth_Lasswell', 'Skltot_Lasswell', 'Nation_Lasswell', 'Dav_GI',  \n",
    "        'Enlgain_Lasswell', 'Enlloss_Lasswell', 'Enlends_Lasswell', 'Enlpt_Lasswell', 'Enloth_Lasswell', 'Enltot_Lasswell', 'Sklasth_Lasswell', 'Timespc_Lasswell',\n",
    "         'objects_component',\n",
    "         'cogproc', 'insight', 'cause', 'discrep',\n",
    "         'Trngain_Lasswell', 'Trnloss_Lasswell', 'Tranlw_Lasswell', 'Arenalw_Lasswell', \n",
    "       'tentat', 'certain', 'differ', 'percept',\n",
    "       'see', 'hear', 'feel', 'bio', 'body',\n",
    "       'health', 'sexual', 'ingest', 'drives',\n",
    "       'affiliation', 'achieve', 'power', 'reward',\n",
    "       'risk', 'focuspast', 'focuspresent', 'focusfuture',\n",
    "       'relativ', 'motion', 'space', 'time', 'work',\n",
    "       'leisure', 'home', 'money', 'relig', 'death']\n",
    "\n",
    "\n",
    "total = features_pad + features_emotion + mood  + sentiment + social + syntactic + topic\n",
    "affective = features_pad + features_emotion + mood  + sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_group = [affective, social, syntactic, topic, total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['dataset', 'clf', 'best_params', 'n_features', 'features', 'f_score', 'precision', 'recall'])\n",
    "\n",
    "for dataset in datasets:\n",
    "    for feat in features_group:\n",
    "        \n",
    "        # load dataset\n",
    "        data = pd.read_csv('../data/processed/{}.csv'.format(dataset))\n",
    "\n",
    "        X = data[feat]\n",
    "        y = data['label']\n",
    "\n",
    "        # drop high correlated features\n",
    "        # Create correlation matrix\n",
    "        corr_matrix = X.corr().abs()\n",
    "\n",
    "        # Select upper triangle of correlation matrix\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "        # Find features with correlation greater than 0.95\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "        # Drop features \n",
    "        X.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "        dropped_columns = to_drop\n",
    "        non_dropped_columns = [x for x in X.columns if x not in dropped_columns]\n",
    "\n",
    "        # create scaler\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        # fit and transform in one step\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        \n",
    "        for rfe in [False, True]:\n",
    "            for clf_name in ['LogR', 'LinSVM']:\n",
    "                \n",
    "                X_it = X.copy()\n",
    "\n",
    "                selected_features = non_dropped_columns\n",
    "\n",
    "                clf = select_classifier(clf_name)\n",
    "                params = select_params(clf_name)\n",
    "\n",
    "                # create cross validation\n",
    "                cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=24091993)\n",
    "                \n",
    "                # create model\n",
    "                rs = RandomizedSearchCV(clf, params, scoring='f1_weighted', cv=cv, n_jobs=-1, random_state=24091993)\n",
    "\n",
    "                # evaluate model\n",
    "                rs.fit(X_it, y)\n",
    "\n",
    "                \n",
    "\n",
    "                if rfe:\n",
    "                    # create model\n",
    "                    model = select_classifier(clf_name)\n",
    "                    \n",
    "                    model.set_params(**rs.best_params_)\n",
    "\n",
    "                    # create model\n",
    "                    rfecv = RFECV(estimator=model, step=1, cv=cv, scoring='f1_weighted', n_jobs=-1)\n",
    "\n",
    "                    # fit the model on all available data\n",
    "                    rfecv.fit(X_it, y)\n",
    "\n",
    "                    # transform X\n",
    "                    X_it = rfecv.transform(X_it) \n",
    "                    \n",
    "                    # get selected features\n",
    "                    selected_features = [non_dropped_columns[i] for i in range(len(rfecv.support_)) if rfecv.support_[i]]\n",
    "\n",
    "                # create model\n",
    "                model = select_classifier(clf_name)\n",
    "                    \n",
    "                model.set_params(**rs.best_params_)\n",
    "\n",
    "                # evaluate model with selected features through cross validation\n",
    "                scores = cross_validate(model, X_it, y, scoring=['f1_weighted', 'precision_weighted', 'recall_weighted'], cv=cv, n_jobs=-1)\n",
    "\n",
    "                # save results with concat\n",
    "                results = pd.concat([results, pd.DataFrame({'dataset': [dataset], 'clf': [clf_name], 'best_params': [rs.best_params_], 'n_features': [len(selected_features)], 'features': [selected_features], 'f_score': [scores['test_f1_weighted'].mean()], 'precision': [scores['test_precision_weighted'].mean()], 'recall': [scores['test_recall_weighted'].mean()]})], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('results/results_mf_depressionintensity.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $M_{we}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_we = pd.DataFrame(columns=['dataset', 'clf', 'best_params', 'embeddings', 'f_score', 'precision', 'recall'])\n",
    "\n",
    "for dataset in datasets:\n",
    "    # transformer_embeddings = all-mpnet-base-v2\n",
    "    # distil_roberta_embeddings = all-distilroberta-v1\n",
    "    # ft_embeddings = FastText\n",
    "    for embeddings in ['transformer_embeddings', 'distil_roberta_embeddings', 'ft_embeddings']:\n",
    "        \n",
    "        # load dataset\n",
    "        data = pd.read_csv('../data/processed/{}.csv'.format(dataset))\n",
    "\n",
    "        X = np.array(data[embeddings].apply(literal_eval).tolist())\n",
    "        y = data['label']\n",
    "\n",
    "        # create scaler\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        # fit and transform in one step\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        for clf_name in ['LogR', 'LinSVM']:\n",
    "\n",
    "            clf = select_classifier(clf_name)\n",
    "            params = select_params(clf_name)\n",
    "\n",
    "            # create cross validation\n",
    "            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=24091993)\n",
    "\n",
    "            # create model\n",
    "            rs = RandomizedSearchCV(clf, params, scoring='f1_weighted', cv=cv, n_jobs=-1, random_state=24091993)\n",
    "\n",
    "            # evaluate model\n",
    "            rs.fit(X, y)\n",
    "\n",
    "            # create model\n",
    "            model = select_classifier(clf_name)\n",
    "                \n",
    "            model.set_params(**rs.best_params_)\n",
    "\n",
    "            # evaluate model with selected features through cross validation\n",
    "            scores = cross_validate(model, X, y, scoring=['f1_weighted', 'precision_weighted', 'recall_weighted'], cv=cv, n_jobs=-1)\n",
    "\n",
    "            # save results with concat\n",
    "            results_we = pd.concat([results_we, pd.DataFrame({'dataset' : dataset, 'clf': [clf_name], 'best_params': [rs.best_params_], 'embeddings': [embeddings], 'f_score': [scores['test_f1_weighted'].mean()], 'precision': [scores['test_precision_weighted'].mean()], 'recall': [scores['test_recall_weighted'].mean()]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "results_we.to_csv('results/results_we_depressionintensity.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $M_E$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_e = pd.DataFrame(columns=['dataset', 'clf', 'best_params', 'f_score', 'precision', 'recall'])\n",
    "\n",
    "for dataset in datasets:\n",
    "\n",
    "    # load dataset\n",
    "    data = pd.read_csv('../data/processed/{}.csv'.format(dataset))\n",
    "\n",
    "    # get best features\n",
    "    best_features = results_mf[results_mf['dataset'] == dataset].sort_values(by='f_score', ascending=False).iloc[0]['features']\n",
    "\n",
    "    X = data[literal_eval(best_features)]\n",
    "    y = data['label']\n",
    "\n",
    "    # get best embeddings\n",
    "    best_embeddings = 'all-distilroberta-v1'# results_we[(results_we['dataset'] == dataset)].sort_values(by='f_score', ascending=False).iloc[0]['embeddings']\n",
    "\n",
    "    # load embeddings\n",
    "    embeddings = np.array(data[best_embeddings].apply(literal_eval).tolist())\n",
    "\n",
    "    # concatenate features and embeddings\n",
    "    X = np.concatenate((X, embeddings), axis=1)\n",
    "\n",
    "    # create scaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # fit and transform in one step\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    for clf_name in ['LogR', 'LinSVM']:\n",
    "\n",
    "        clf = select_classifier(clf_name)\n",
    "        params = select_params(clf_name)\n",
    "\n",
    "        # create cross validation\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "        # create model\n",
    "        rs = RandomizedSearchCV(clf, params, scoring='f1_weighted', cv=cv, n_jobs=-1, random_state=seed)\n",
    "\n",
    "        # evaluate model\n",
    "        rs.fit(X, y)\n",
    "\n",
    "        # create model\n",
    "        model = select_classifier(clf_name)\n",
    "            \n",
    "        model.set_params(**rs.best_params_)\n",
    "\n",
    "        # evaluate model with selected features through cross validation\n",
    "        scores = cross_validate(model, X, y, scoring=['f1_weighted', 'precision_weighted', 'recall_weighted'], cv=cv, n_jobs=-1)\n",
    "\n",
    "        # save results with concat\n",
    "        results_e = pd.concat([results_e, pd.DataFrame({'dataset' : dataset, 'clf': [clf_name], 'best_params': [rs.best_params_], 'f_score': [scores['test_f1_weighted'].mean()], 'precision': [scores['test_precision_weighted'].mean()], 'recall': [scores['test_recall_weighted'].mean()]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "results_e.to_csv('results/results_e_depressionintensity.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvdepressiontext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
